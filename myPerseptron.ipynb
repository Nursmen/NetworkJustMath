{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "     Input Layer (2 neurons)\n",
    "            ||\n",
    "            \\/\n",
    "     Hidden Layer (3 neurons)\n",
    "            ||\n",
    "            \\/\n",
    "     Output Layer (1 neuron)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97873798 1.37889519 2.74279033 3.14294754]]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(1, 2)\n",
    "b = np.random.randn(1, 1)\n",
    "\n",
    "print(np.dot(W,x.T)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.86755799  2.2408932   4.10845119]\n",
      " [ 0.          0.95008842 -0.97727788 -0.02718946]\n",
      " [ 0.         -0.10321885 -0.15135721 -0.25457606]]\n",
      "\n",
      "[[0.         0.7535622  0.55922202 1.31278422]]\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.randn(3, 2)\n",
    "b1 = np.zeros((3,1))\n",
    "W2 = np.random.randn(1, 3)\n",
    "b2 = np.zeros((1,1))\n",
    "\n",
    "print(np.dot(W1,x.T)+b1)\n",
    "print()\n",
    "print(np.dot(W2,np.dot(W1,x.T)+b1)+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.71170324 0.71506399 0.84381919]]\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1,x.T)\n",
    "A1 = relu(Z1)\n",
    "Z2 = np.dot(W2,A1)+b2\n",
    "A2 = sigmoid(Z2)\n",
    "\n",
    "print(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bceloss(y_hat, y): \n",
    "    y_hat = np.clip(y_hat, 1e-8, 1 - 1e-8)\n",
    "    y = y.T\n",
    "    return -np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2253656216592548"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = bceloss(A2, y)\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Дизайн без названия.png' width='55%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05736915  0.05702417]\n",
      " [ 0.         -0.01038182]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "[[ 0.02777559]\n",
      " [-0.01038182]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "m=y.shape[0]\n",
    "\n",
    "dA2 = -(y.T/A2) + ((1-y.T)/(1-A2))\n",
    "dZ2 = dA2 * (A2 * (1-A2))\n",
    "dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "dA1 = np.dot(W2.T, dZ2)\n",
    "dZ1 = dA1 * np.where(A1 > 0, 1, 0)\n",
    "# dZ1[dZ1 <= 0] = 1e-8\n",
    "dW1 = (1/m) * np.dot(dZ1, x)\n",
    "db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "print(dW1)\n",
    "print()\n",
    "print(db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.57246697, -0.06847685,  0.        ]]),\n",
       " array([[0.4105985 , 0.14404357, 1.45427351]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.7535622  0.55922202 1.31278422]]\n",
      "[[0 1 1 0]]\n",
      "\n",
      "[[-0.09712501  0.15178863 -0.21634948  0.03256416]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "\n",
    "print(np.dot(W2,np.dot(W1,x.T)+b1)+b2)\n",
    "\n",
    "W1 = W1 - learning_rate * dW1\n",
    "b1 = b1 - learning_rate * db1\n",
    "W2 = W2 - learning_rate * dW2\n",
    "b2 = b2 - learning_rate * db2\n",
    "\n",
    "print(y.T)\n",
    "print()\n",
    "print(np.dot(W2,np.dot(W1,x.T)+b1)+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26970974 -0.99641848 -1.71051536 -2.4372241 ]]\n",
      "1.0\n",
      "[[-0.37346062 -2.03910763 -3.09937423 -4.76502124]]\n",
      "0.9995\n",
      "[[-0.27333926 -2.77494719 -4.1824053  -6.68401322]]\n",
      "0.999\n",
      "[[ 0.17075003 -2.99338294 -4.7498757  -7.91400867]]\n",
      "0.9985\n",
      "[[ 1.09848148 -2.4844941  -4.59268353 -8.17565911]]\n",
      "0.998\n",
      "[[ 2.64910841 -1.03899247 -3.50235702 -7.1904579 ]]\n",
      "0.9975\n",
      "[[ 4.96146375  1.55177829 -1.27105375 -4.68073921]]\n",
      "0.997\n",
      "[[ 8.17396054  5.49584351  2.30844009 -0.36967694]]\n",
      "0.9965\n",
      "[[12.4245925  11.00059827  7.44271057  6.01871635]]\n",
      "0.996\n",
      "[[17.85093452 18.27280821 14.33771675 14.75959044]]\n",
      "0.9955\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    m=y.shape[0]\n",
    "\n",
    "    dA2 = -(y.T/A2) + ((1-y.T)/(1-A2))\n",
    "    dZ2 = dA2 * (A2 * (1-A2))\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * np.where(Z1 > 0, 1, 0)\n",
    "    dZ1[dZ1 <= 0] = 1e-8\n",
    "    dW1 = (1/m) * np.dot(dZ1, x)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    learning_rate = 1 - i/2000\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(np.dot(W2,np.dot(W1,x.T)+b1)+b2)\n",
    "\n",
    "        print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.504754759999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.49584351  - 11.00059827  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NursikJunior:\n",
    "    def __init__(self, units, learning_rate=1):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "\n",
    "        for i in range(len(units)-1):\n",
    "            self.W.append(np.random.randn(units[i+1], units[i]) * 0.01)\n",
    "            self.b.append(np.zeros((units[i+1], 1)))\n",
    "\n",
    "        self.A = []\n",
    "        self.Z = []\n",
    "        \n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.A = []\n",
    "        self.Z = []\n",
    "        \n",
    "        Z_last = x.T\n",
    "        self.A.append(Z_last)\n",
    "\n",
    "        # print('forward: ',self.W)\n",
    "        for i in range(len(self.W)):\n",
    "            Z = np.dot(self.W[i], Z_last) + self.b[i]\n",
    "            self.Z.append(Z)\n",
    "            A = self.relu(Z) if i < len(self.W) - 1 else self.sigmoid(Z)\n",
    "            self.A.append(A)\n",
    "            Z_last = A\n",
    "            \n",
    "        return self.A[-1]\n",
    "    \n",
    "    def backward(self, y):\n",
    "\n",
    "        # print('backfard: ',self.W)\n",
    "        for i in range(len(self.W)-1, -1, -1):\n",
    "            if i == len(self.W) - 1:\n",
    "                dA = -(1/y.shape[0]) * (y.T/self.A[i+1] - (1-y).T/(1-self.A[i+1]))\n",
    "                dZ = dA * self.A[i+1] * (1 - self.A[i+1])\n",
    "            else:\n",
    "                dA = np.dot(self.W[i+1].T, dZ)\n",
    "                dZ = dA*np.where(self.Z[i] > 0, 1, 0)\n",
    "            dW = (1/y.shape[0]) * np.dot(dZ, self.A[i].T)\n",
    "            db = (1/y.shape[0]) * np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "            self.W[i] = self.W[i] - self.learning_rate * dW\n",
    "            self.b[i] = self.b[i] - self.learning_rate * db\n",
    "\n",
    "        # print(self.W)\n",
    "    def predict(self, x):\n",
    "        return self.forward(x) > 0.5\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        y_hat = np.clip(y_hat, 1e-8, 1 - 1e-8)\n",
    "        y =y.T\n",
    "        return -(1/y.shape[0]) * np.sum(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [2,3,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.772588677750069\n",
      "2.7725870124633674\n",
      "2.7725777857251064\n",
      "2.77220572514621\n",
      "0.03694302799189906\n",
      "0.011903753765027272\n",
      "0.007054564915184421\n",
      "0.005000482156754122\n",
      "0.0038695953002968737\n",
      "0.0031538819744965536\n",
      "[[0.00128791 0.99995787 0.99995806 0.00128791]]\n"
     ]
    }
   ],
   "source": [
    "NJ = NursikJunior(units, 1)\n",
    "for i in range(10000):\n",
    "\n",
    "    NJ.forward(x)\n",
    "    # print(NJ.A[-1])\n",
    "\n",
    "    NJ.backward(y)\n",
    "    if i % 1000 == 0:\n",
    "\n",
    "        print(NJ.loss(NJ.A[-1], y))\n",
    "        # if np.round(NJ.A[-1][0][0],3) == 0.5 and np.round(NJ.A[-1][0][1],3) == 0.5:\n",
    "        #     break\n",
    "\n",
    "\n",
    "print(NJ.A[-1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm part\n",
    "\n",
    "<img src='justtemp (2).png' width='55%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchNorm(x, gamma=None, beta=None):\n",
    "    mean = np.mean(x, axis=0)\n",
    "    varience = np.std(x, axis=0)\n",
    "\n",
    "    normalized = (x - mean) / np.sqrt(varience + 1e-8)\n",
    "    result = gamma*normalized + beta\n",
    "\n",
    "    return result, normalized, gamma, beta, varience, mean\n",
    "\n",
    "\n",
    "def batchnorm_backward(a, a_hat, da_wave, gamma, beta, varience, mean):\n",
    "    dbeta = np.sum(da_wave, axis=0)\n",
    "    dgamma = np.sum(da_wave * a_hat, axis=0)\n",
    "\n",
    "    da_hat = gamma * da_wave\n",
    "    dvarience =  da_hat * (-1/2) * a_hat/(varience**2 + 1e-8)\n",
    "    dmean = dvarience * np.sum(2/a_hat.shape[0] * (a - mean), axis=0) + np.sum(da_hat * (-1/np.sqrt(varience**2 + 1e-8)), axis=0)\n",
    "  \n",
    "    da = dmean / a_hat.shape[0] + dvarience * 2/a_hat.shape[0] * (a - mean) + da_hat / (1/np.sqrt(varience**2 + 1e-8))\n",
    "\n",
    "    return dbeta, dgamma, da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7727333312068674\n",
      "[[0.5        0.49992006 0.49990998 0.49990232]]\n",
      "\n",
      "1.054178127960229\n",
      "[[0.25593757 0.76691356 0.76691356 0.20370489]]\n",
      "\n",
      "0.5994418280033131\n",
      "[[0.16448579 0.86006326 0.86006326 0.11151297]]\n",
      "\n",
      "0.4107733811577357\n",
      "[[0.1203503  0.90188347 0.90188347 0.07318559]]\n",
      "\n",
      "0.31030445712005944\n",
      "[[0.09480426 0.92496023 0.92496023 0.05322265]]\n",
      "\n",
      "0.2485613459935225\n",
      "[[0.07823172 0.93942923 0.93942923 0.04125904]]\n",
      "\n",
      "0.2069832202375455\n",
      "[[0.06663116 0.94929847 0.94929847 0.03339405]]\n",
      "\n",
      "0.1771614261234073\n",
      "[[0.05806174 0.95644043 0.95644043 0.02787641]]\n",
      "\n",
      "0.15476503848715473\n",
      "[[0.05147333 0.96183924 0.96183924 0.0238156 ]]\n",
      "\n",
      "0.13734663714155465\n",
      "[[0.04624964 0.96605912 0.96605912 0.02071526]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.randn(3, 2)* 0.01\n",
    "b1 = np.zeros((3,1))\n",
    "W2 = np.random.randn(5, 3)* 0.01\n",
    "b2 = np.zeros((5,1))\n",
    "W3 = np.random.randn(1, 5)* 0.01\n",
    "b3 = np.zeros((1,1))\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "gamma1 = 1\n",
    "beta1 = 0\n",
    "gamma2 = 1\n",
    "beta2 = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "\n",
    "    Z1 = np.dot(W1,x.T)+b1\n",
    "    N1, normalized1, gamma1, beta1, varience1, mean1 = BatchNorm(Z1, gamma1, beta1)\n",
    "    A1 = relu(N1)\n",
    "    Z2 = np.dot(W2,A1)+b2\n",
    "    N2, normalized2, gamma2, beta2, varience2, mean2 = BatchNorm(Z2, gamma2, beta2)\n",
    "    A2 = relu(N2)\n",
    "    Z3 = np.dot(W3,A2)+b3\n",
    "\n",
    "    \n",
    "    try: A3 = sigmoid(Z3)\n",
    "    except: print(i);break\n",
    "\n",
    "    loss = bceloss(A3, y)\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "        print(A3)\n",
    "        print()\n",
    "\n",
    "\n",
    "    dA3 = - ( y.T/A3) + (1-y.T)/(1-A3)\n",
    "    dZ3 = dA3 * A3 * (1-A3)\n",
    "    dW3 = (1/y.shape[0]) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1/y.shape[0]) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dN2 = dA2 * np.where(Z2 > 0, 1, 0)\n",
    "    dbeta2, dgamma2, dZ2 = batchnorm_backward(Z2, normalized2, dN2, gamma2, beta2, varience2, mean2)\n",
    "    # dZ2[dZ2 <= 0] = 1e-8\n",
    "    dW2 = (1/y.shape[0]) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/y.shape[0]) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dN1 = dA1 * np.where(Z1 > 0, 1, 0)\n",
    "    dbeta1, dgamma1, dZ1 = batchnorm_backward(Z1, normalized1, dN1, gamma1, beta1, varience1, mean1) \n",
    "    # dZ1[dZ1 <= 0] = 1e-8\n",
    "    dW1 = (1/y.shape[0]) * np.dot(dZ1, x)\n",
    "    db1 = (1/y.shape[0]) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "\n",
    "    gamma1 = gamma1 - learning_rate * dgamma1\n",
    "    beta1 = beta1 - learning_rate * dbeta1\n",
    "    gamma2 = gamma2 - learning_rate * dgamma2\n",
    "    beta2 = beta2 - learning_rate * dbeta2\n",
    "\n",
    "    if A3[0][0] == 0.5 and A3[0][1] == 0.5:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanik part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanik = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "titanik.fillna(0, inplace=True)\n",
    "\n",
    "titanik.drop(['Ticket', 'Name', 'Cabin', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanik = pd.get_dummies(titanik, drop_first=True)\n",
    "x = titanik.drop(['Survived'], axis=1).to_numpy()\n",
    "y = titanik['Survived'].to_numpy()\n",
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 22.0, 1, 0, 7.25, True, False, False, True],\n",
       "       [1, 38.0, 1, 0, 71.2833, False, True, False, False],\n",
       "       [3, 26.0, 0, 0, 7.925, False, False, False, True]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  73.28710664,  883.30712354,   36.41428291,   26.60826939,\n",
       "       1766.87993463,   24.0208243 ,   12.9614814 ,    8.77496439,\n",
       "         25.37715508])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.float64(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x/np.linalg.norm(np.float64(x), axis=0)\n",
    "x = np.int64(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.5924744066583\n",
      "607.2601674397192\n",
      "601.3520190179339\n",
      "597.9575658428776\n",
      "595.9919879888412\n",
      "594.8361394757412\n",
      "594.1246114079502\n",
      "593.6141522941086\n",
      "593.0440733052071\n",
      "591.6710984931344\n",
      "584.9999114783645\n",
      "570.2887587219384\n",
      "565.3855799187542\n",
      "563.2383572379917\n",
      "561.715789735524\n",
      "560.5573418180124\n",
      "559.6626820234635\n",
      "558.9469289343199\n",
      "558.3494100139721\n",
      "557.8201220899734\n",
      "557.3245421519098\n",
      "556.8350120261199\n",
      "556.3212308501851\n",
      "555.77873396264\n",
      "555.1877780537114\n",
      "554.5350768147205\n",
      "553.810621945234\n",
      "553.0068903134024\n",
      "552.129110262936\n",
      "551.1913862481314\n",
      "550.1983150737071\n",
      "549.2392878250499\n",
      "548.3550064772483\n",
      "547.575808550277\n",
      "546.8955613671613\n",
      "546.2761126069314\n",
      "545.6983171823243\n",
      "545.121005204257\n",
      "544.5098971186196\n",
      "543.8447535642459\n",
      "543.1128737708814\n",
      "542.2991853587032\n",
      "541.371068153333\n",
      "540.3044942709071\n",
      "539.0875106446689\n",
      "537.6972574811008\n",
      "536.0694226986004\n",
      "534.1650253722361\n",
      "532.0073029495691\n",
      "529.4942993745778\n",
      "526.5406927945882\n",
      "523.0546197235885\n",
      "519.0483177379191\n",
      "514.3909071920165\n",
      "509.0098834600464\n",
      "502.79284400824014\n",
      "495.5378786340067\n",
      "487.47271406394213\n",
      "479.3571650556079\n",
      "470.08452574597993\n",
      "461.56076878757773\n",
      "453.9892712570652\n",
      "447.4686414511365\n",
      "441.712918976948\n",
      "436.6390375797622\n",
      "432.1828900891047\n",
      "428.27765854238874\n",
      "424.4254965738613\n",
      "421.03976938917594\n",
      "418.6294384802546\n",
      "416.64873658138686\n",
      "414.65354077030304\n",
      "413.2962431242109\n",
      "410.92817418141414\n",
      "410.2384162463294\n",
      "406.9519099836218\n",
      "405.48242248922475\n",
      "404.49428096071665\n",
      "402.94420045932304\n",
      "402.14772935046454\n",
      "401.2903669729973\n",
      "400.3262437569206\n",
      "398.280068450479\n",
      "397.93317215888476\n",
      "397.5230401148674\n",
      "395.578441795288\n",
      "394.14035571820995\n",
      "393.47627744673036\n",
      "393.03780198205635\n",
      "392.0437639883297\n",
      "391.1599736028532\n",
      "390.5410856921893\n",
      "391.3822245031895\n",
      "389.9654163339906\n",
      "387.78017146354944\n",
      "390.1904917598622\n",
      "389.3044357383536\n",
      "385.7203122971101\n",
      "386.2397096820312\n",
      "385.6131406545011\n"
     ]
    }
   ],
   "source": [
    "units = [9,25,5,1]\n",
    "\n",
    "NJ = NursikJunior(units, 1)\n",
    "\n",
    "for i in range(100000):\n",
    "\n",
    "    NJ.forward(x)\n",
    "    # print(NJ.A[-1])\n",
    "\n",
    "    NJ.backward(y)\n",
    "    if i % 1000 == 0:\n",
    "\n",
    "        print(NJ.loss(NJ.A[-1], y))\n",
    "        # if np.round(NJ.A[-1][0][0],3) == 0.5 and np.round(NJ.A[-1][0][1],3) == 0.5:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103254769921436"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = NJ.predict(x)\n",
    "np.sum(prediction.reshape(891,1)==y)/y.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13d23e047223dc84a1102dc5c766dcad7992afc98d26331706d77d9a7e59ca18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
